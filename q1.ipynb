{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 — Fine-tune a pretrained ViT on CIFAR-10 (Colab-ready)\n",
    "\n",
    "This notebook fine-tunes a pretrained Vision Transformer (`vit_b_16`) from `torchvision` on CIFAR-10.\n",
    "\n",
    "Notes:\n",
    "- Resize CIFAR images to 224×224 expected by the pretrained ViT.\n",
    "- Use standard augmentations, AdamW, and a cosine LR scheduler.\n",
    "- Save best checkpoint `best_vit_cifar10.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run first cell in Colab)\n",
    "!pip install -q timm einops albumentations==1.3.1 torchmetrics\n",
    "\n",
    "# NOTE: Colab usually has a suitable torch+cuda build preinstalled. If not, you may need to install torch compatible with the runtime GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: CIFAR-10\n",
    "- Resize to 224x224 (ViT pretraining size)\n",
    "- Basic augmentations for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ColorJitter(0.1,0.1,0.1,0.02),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.4914,0.4822,0.4465), std=(0.247,0.243,0.261))\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=(0.4914,0.4822,0.4465), std=(0.247,0.243,0.261))\n",
    "])\n",
    "\n",
    "class TransformCIFAR10(CIFAR10):\n",
    "    def __init__(self, root, train, transform, download=False):\n",
    "        super().__init__(root=root, train=train, transform=None, download=download)\n",
    "        self.alb_transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx], int(self.targets[idx])\n",
    "        img = self.alb_transform(img)\n",
    "        return img, label\n",
    "\n",
    "def get_loaders(batch_size=64, num_workers=2):\n",
    "    train_ds = TransformCIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "    val_ds = TransformCIFAR10(root='./data', train=False, download=True, transform=val_transform)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "train_loader, val_loader = get_loaders(batch_size=128, num_workers=4)\n",
    "print('Train batches:', len(train_loader), 'Val batches:', len(val_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: load pretrained ViT and adapt head for 10 classes\n",
    "- We use `torchvision.models.vit_b_16` with pretrained weights (if available in your torchvision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "weights = None\n",
    "try:\n",
    "    # If torchvision provides pretrained weights in this environment\n",
    "    weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "except Exception:\n",
    "    weights = None\n",
    "\n",
    "print('Using weights:', weights)\n",
    "model = vit_b_16(weights=weights).to(device)\n",
    "# Replace head\n",
    "in_features = model.heads.head.in_features if hasattr(model, 'heads') else model.head.in_features\n",
    "try:\n",
    "    # torchvision ViT has `heads` module\n",
    "    model.heads.head = nn.Linear(in_features, 10)\n",
    "except Exception:\n",
    "    model.head = nn.Linear(in_features, 10)\n",
    "model = model.to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "EPOCHS = 20\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    acc = MulticlassAccuracy(num_classes=10).to(device)\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc.update(preds, labels)\n",
    "            n += imgs.size(0)\n",
    "    return total_loss / n, acc.compute().item()\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    acc = MulticlassAccuracy(num_classes=10).to(device)\n",
    "    running_loss = 0.0\n",
    "    n = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc.update(preds, labels)\n",
    "        n += imgs.size(0)\n",
    "    return running_loss / n, acc.compute().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (short example). Increase EPOCHS to 50-100 for better results.\n",
    "best_acc = 0.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch:03d} | train_loss {train_loss:.4f} acc {train_acc:.4f} | val_loss {val_loss:.4f} acc {val_acc:.4f} | time {time.time()-t0:.1f}s\")\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({'model_state': model.state_dict(), 'epoch': epoch, 'best_acc': best_acc}, 'best_vit_cifar10.pth')\n",
    "print('Best val acc:', best_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Increase `EPOCHS` and consider techniques such as MixUp, CutMix, and longer training for higher accuracy.\n",
    "- If the environment does not have `ViT_B_16` weights pre-downloaded, `weights=None` will use randomly initialized ViT; to use ImageNet pretrained weights ensure torchvision and internet access permit download."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
